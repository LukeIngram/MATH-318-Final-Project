---
title: "Challenge 2: K-Nearest-Neighbors"
author: "Luke Ingram, Sahil Gill" 
subtitle: "MATH 318 - Winter 2023"
output: html_notebook
---

```{r}
library("reticulate")
Sys.setenv(RETICULATE_PYTHON = "../venv/bin/python3") # Set python env
```

```{python}
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import LabelEncoder,MinMaxScaler
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt 
import pandas as pd
import numpy as np 
import cv2
import glob
import random
```

## Section 1 - Loading the Data

```{python}
dirName = "../src/data/archive/zero-indexed-files.txt"
imgPath = "../src/data/archive/Garage_classification/load/"

df_raw = pd.read_csv(dirName,sep=' ')
df_raw['image'] = imgPath + df_raw['image'].astype(str)

plt.clf()
plt.rc('axes', axisbelow=True)
plt.grid(linestyle='dotted')
temp = plt.bar(list(range(6)),
                np.unique(df_raw['class'],return_counts=True)[1])
_ = plt.title("Distribution of Classes in Raw Dataset")
_ = plt.xlabel("Class")
_ = plt.ylabel("Count")

plt.show()
```

In our dataset the class labels are assigned as follows:

0.  Glass
1.  Paper
2.  Cardboard
3.  Plastic
4.  Metal
5.  Trash

Above, we've prepared a dataframe containing filepaths and their respective classes. Now we need to extract our design matrix.

Previously, we introduced SIFT, an algorithm for keypoint and image descriptor generation. The algorithm outputs a keypoint object, a datatype that efficiently encodes both the keypoints and image descriptors for each image. However, if we use KNN, we must transform our data into a discrete set of features whose entries can be evaluated with a distance metric.

## Section 2 - Data Quantization

The process of generating said feature space involves three steps.

1.  Extracting Keypoints & Descriptors: SIFT Algorithm covered in the last Challenge
2.  Clustering (Feature Reduction): TODO: description
3.  Normalization & Discretization: TODO: description

### Section 2.1 - K-Means Clustering

TODO: Introduct K-Means clustering

TODO: Introduce Elbow-Method

TODO bag of visual words quantitization

### Section 2.3 - Normalization & Discretization

TODO Image histograms & normalization

## Section 3 - KNN Classification

Now, we classify:

TODO

### Section 3.1 - K-Fold Cross Validation

```{python}

```

### Section 3.2 - Classifying with Optimized K

## Section 4 - Raw Pixels

TODO: REVISIT THE RAW PIXEL APPROACH & COMPARE TO ABOVE
