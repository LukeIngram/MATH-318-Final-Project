{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b83ee6f",
   "metadata": {},
   "source": [
    "# **Challenge 3 - Neural Networks**\n",
    "* Sahil Gill, Luke Ingram\n",
    "* MATH 318 - Winter 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501ff258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a1cdf36",
   "metadata": {},
   "source": [
    "## **Section 1 - Why Neural Nets?**\n",
    "\n",
    "From the previous challenge, we can conclude that classifying these images is difficult. Despite our best attempts at expanding the K-Nearest-Neighbors algorithm, our model's accuracy was is not what's desired from a classifier. So, once again, we try a more sophisticated approach. \n",
    "\n",
    "Which brings us to Neural Networks. Neural networks are complex, but flexible, and have soared in popularity over the last 10-15 years. One specific type of Neural Net, the **Convolutionary Neural Network** designed for image processing, is what we will be using to tackle the challenge of trash classification. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27e05251",
   "metadata": {},
   "source": [
    "## **Section 2 - The Architecture**\n",
    "\n",
    "### **Section 2.1 - MobileNetV2**\n",
    "\n",
    "TODO: INTRODUCE MOBILENETV2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa805c67",
   "metadata": {},
   "source": [
    "### **Section 2.2 - Transfer Learning**\n",
    "\n",
    "## **Section 3 - MobileNetV2 in Action**\n",
    "\n",
    "Now it's time to put this into action. \n",
    "\n",
    "Before we begin, we need to load & normalize our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610eb1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data \n",
    "dirName = \"../src/data/archive/zero-indexed-files.txt\"\n",
    "imgPath = \"../src/data/archive/Garbage_classification/load/\"\n",
    "\n",
    "df = pd.read_csv(dirName,sep=' ')\n",
    "\n",
    "df['image'] = imgPath + df['image'].astype*(str)\n",
    "df['image'] = df['image'].apply(lambda x: cv2.resize(cv2.imread(x),(224,224)))\n",
    "print(df.head()) #DEBUG\n",
    "\n",
    "train_X,test_X,train_Y,test_Y = train_test_split(df['image'],df['class'],\n",
    "                                                 test_size=0.20,random_state=42,stratify=df['class'])\n",
    "\n",
    "\n",
    "train_X,val_X,val_X,val_Y = train_test_split(train_X,train_Y,\n",
    "                                               test_size=0.20,random_state=42,stratify=train_Y)\n",
    "\n",
    "# Normalize data \n",
    "train_X = train_X/255.0 \n",
    "test_X = test_X/255.0\n",
    "val_X = val_X/255.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce99887d",
   "metadata": {},
   "source": [
    "### **Section 3.1 - Initializing MobileNetV2**\n",
    "\n",
    "Keras provides us with an implementation of the MobileNetV2 network, we only have to specify the hyperparameters as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d3e57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch network from keras, & define custom params. \n",
    "# This is a pre-trained model,but we remove the last layer \n",
    "# & train it ourselves to fit out problem\n",
    "model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
    "    input_shape = None, # our images are already the required shape (244x244)\n",
    "    alpha = 1.0, # using default input width\n",
    "    include_top = True, #include fully-connected input layer\n",
    "    weights = 'imagenet', # Default weights\n",
    "    input_tensor = None, # using default input tensor structure\n",
    "    pooling = None, # not using this feature\n",
    "    classes = 1000, # default for MobileNet\n",
    "    classifier_activation = 'softmax' #specify activation function of output layer\n",
    ")   \n",
    "\n",
    "# Make sure existing layers (convolutionary & pooling) remain untouched\n",
    "for layer in model.layers: \n",
    "    layer.trainable = False "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccd09416",
   "metadata": {},
   "source": [
    "### **Section 3.2 - Customized Output Layers**\n",
    "\n",
    "TODO: Explain the transfer learning step & why we are using this many layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc352ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_layer = model.layers[-2].output\n",
    "\n",
    "output_layer = tf.keras.layers.Dense(144,activation='relu')(final_layer)\n",
    "output_layer = tf.keras.layers.Dense(72,activation='relu')(final_layer)\n",
    "output_layer = tf.keras.layers.Dense(7,activation='softmax')(final_layer)\n",
    "\n",
    "# add it back to model\n",
    "model = tf.keras.Model(inputs = model.layers[0].input,outputs = output_layer)\n",
    "\n",
    "# Compile final model\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='SGD', # Stochastic- Gradient - Descent\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e41299ed",
   "metadata": {},
   "source": [
    "### **Section 3.3 - Training the Model**\n",
    "\n",
    "TODO: explain stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ed8fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to float for tensor conversion \n",
    "train_X = np.asarray(list(train_X),dtype='float32')\n",
    "test_X = np.asarray(list(test_X),dtype='float32')\n",
    "val_X = np.asarray(list(val_X),dtype='float32')\n",
    "\n",
    "\n",
    "training_history = model.fit(train_X,train_Y,epochs = 30,validation_data=(val_X,val_Y))\n",
    "\n",
    "plt.clf()\n",
    "plt.rc('axes', axisbelow=True)\n",
    "plt.grid(linestyle='dotted')\n",
    "plt.plot(training_history['accuracy'],label='accuracy')\n",
    "plt.plot(training_history['val_accuracy'],label = 'val_accuracy')\n",
    "_ = plt.xlabel('Epoch')\n",
    "_ = plt.ylabel('Accuracy')\n",
    "_ = plt.title('Training & Validation Accuracy During Training')\n",
    "\n",
    "plt.show() # TODO MAKE PLOT FOR TRAINING & VALIDATION ACCURACY\n",
    "\n",
    "\n",
    "model.evaluate(test_X,test_Y) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e26311a",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "191cdd59",
   "metadata": {},
   "source": [
    "## **Section 4 - Results & Comparison with Previous Methods**\n",
    "\n",
    "TODO: load a few classified results & display"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
