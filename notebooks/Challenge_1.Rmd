---
title: 'Challenge 1: Finding our Feature Space'
author: "Sahil Gill, Luke Ingram"
subtitle: "MATH 318 - Winter 2023"
output:
  pdf_document: default
  html_notebook: default
---

```{r}
library("reticulate")
Sys.setenv(RETICULATE_PYTHON = "../venv/bin/python3") # Set python env
```

```{python}
from sklearn.decomposition import PCA
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt 
import numpy as np 
import cv2
import glob
import random
```

## Section 1 - Introduction

### The Dataset:

We'll be using the **Garbage Classification** dasaset linked here: <https://www.kaggle.com/datasets/asdasdasasdas/garbage-classification>

This is a supervised learning dataset contains 2527 images belonging to six classes. Cardboard (393), glass (491), metal (400), paper(584), plastic (472) and trash(127).

Here's a sample image from each class:

```{python}

# Define paths
basepath = "../src/data/archive/Garbage_classification/"
fnames = ["cardboard1.jpg","glass6.jpg","metal5.jpg",
          "paper1.jpg","plastic1.jpg","trash2.jpg"]
    
# Get samples
samples = [
    cv2.imread(f"{basepath}cardboard/{fnames[0]}"),
    cv2.imread(f"{basepath}glass/{fnames[1]}"),
    cv2.imread(f"{basepath}metal/{fnames[2]}"),
    cv2.imread(f"{basepath}paper/{fnames[3]}"),
    cv2.imread(f"{basepath}plastic/{fnames[4]}"),
    cv2.imread(f"{basepath}trash/{fnames[5]}")
]

# Define & Display
fig,axes = plt.subplots(2,3,subplot_kw={'xticks':(),'yticks':()})

for sample,ax,fname in zip(samples,axes.flatten(),fnames):
    ax.imshow(cv2.cvtColor(sample, cv2.COLOR_BGR2RGB))
    ax.set_title(fname)

plt.show()
```

As you may have guessed, we are tackling a classification problem.

But we've got all these images, where do we start?

## Section 2 - Extracting Information from Images

Before we make any predictions, we need to understand how we obtain real-valued information from our images. There are a number of approaches we can take:

### Section 2.1 - Raw Pixel Data

If you've ever played around with the MNIST handwritten digit recognition dataset, or watched some introductory videos about computer vision, then an intuitively simple approach would be to enumerate all of the pixel data into a massive array.

Since all the images in our dataset are 512x384, converting all our images to grayscale yields a feature space of 196608. Now if we consider our three color channels, our space would grow to a monstrous 589824 features.

We may perform dimensional reduction methods such as PCA to reduce this number. For example, taking a 1000-sample subset of our training data.

```{python}
# NOTE: DO NOT RUN OUTSIDE OF HEAVY COMPUTE ENVIRONMENT

# Load dataset
imgPaths = glob.glob("../src/data/archive/Garbage_classification/load/*.jpg")
X_raw = np.array([np.array(cv2.imread(img)) for img in random.choices(imgPaths,k=1000])
X_data = X_raw.flatten().reshape(1000,589824) # flatten & reshape to retain features

# Reduce down to 95% explained variance
scaler = MinMaxScaler()
#X_scaled = scaler.fit_transform(X_data) #<--- uncommnet to run
pca = PCA(n_components = 0.95) # n_components < 1 converts to pc's needed for that expl. var.
#pca.fit(X_scaled) #<------ uncommnet to run 
#X_reduced = pca.transform(X_scaled) #<------ uncommnet to run x

print(f"Dimensions of data after PCA: {X_reduced.shape}")
```

With PCA, we were able to reduce our dimensions to only \_\_! All while retaining 95% of our explained variance!

Evaluation of the Raw Pixel Data method is to come, but first we explore a more sophisticated approach.

### Section 2.2 - Keypoints

TODO gentile introduction to keypoints in images (hopefully using examples

...

How do we obtain these keypoints?

### Section 2.3 - SIFT, SURF, & FAST

TODO: what is a feature descriptor?

**SIFT (Scale Invariant Feature Transform)**:

TODO (EXPLANATION)

```{python}
#TODO FIND KEYPOINTS AND SAVE THEM TO CSV (easier transition to R)

```

**SURF (Speeded-Up Robust Features):**

TODO (EXPLANATION)

```{python}
#TODO FIND KEYPOINTS AND SAVE THEM TO CSV (easier transition to R)
```

**FAST (Features from Accelerated Segment Test):**

TODO (EXPLANATION)

```{python}
#TODO FIND KEYPOINTS AND SAVE THEM TO CSV (easier transition to R)
```
